{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import itertools\n",
    "import math\n",
    "from copy import copy\n",
    "import pdb\n",
    "\n",
    "### Create selection of SNPs\n",
    "def select_snps(z, subset):\n",
    "    return [z[i] for i in subset]\n",
    "\n",
    "#example\n",
    "# for subset in it.combinations(range(len(z1)),3):\n",
    "#     print subset, select_snps(z1, subset)    \n",
    "\n",
    "\n",
    "\n",
    "### Select covariance submatrix\n",
    "\n",
    "def select_cov(cov, subset):\n",
    "    return cov[numpy.ix_(subset,subset)]\n",
    "\n",
    "#example   \n",
    "#select_cov(LD_tss_1, (0,1,5))\n",
    "\n",
    "### Calculate Bayes Factor\n",
    "\n",
    "def calc_BF(z, cov,n,v=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the Bayes factor of a single set of candidate SNPs effect sizes z,\n",
    "    covariance matrix cov, a prior variance on beta v, and a sample\n",
    "    size n.\n",
    "    \"\"\"\n",
    "    z = numpy.matrix(z)\n",
    "    z = z.T\n",
    "    v_matrix = numpy.matrix(numpy.eye(len(z)) * v)\n",
    "    coeff = 1. / math.sqrt(numpy.linalg.det((numpy.matrix(numpy.eye(len(z))) + n * v_matrix * numpy.matrix(cov))))\n",
    "    exponent = 0.5* z.T * numpy.matrix(numpy.linalg.pinv((n*v_matrix).I + cov)) * z\n",
    "    return numpy.array(math.log(coeff) + exponent)[0][0]\n",
    "\n",
    "# example\n",
    "# subset = (0,1,5,8)\n",
    "# cov = select_cov(LD_tss_1, subset)\n",
    "# z = select_snps(z1, subset)\n",
    "# v = np.eye(len(z))/1000\n",
    "# n = 1000\n",
    "# calc_BF(z,cov,v,n)\n",
    "\n",
    "def calc_prior(x,m,prior='binomial'):\n",
    "    if prior == 'binomial':\n",
    "        p = 1./m\n",
    "        l = len(x)\n",
    "        return p**l * (1-p)**(m-l)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# example\n",
    "# calc_prior((1,3,5),30)\n",
    "    \n",
    "def calc_posterior(variant_set_BF,prior='binomial'):\n",
    "    \n",
    "    priors = [math.log(calc_prior(x[0],30)) for x in variant_set_BF]\n",
    "    \n",
    "    log_bayes_factors = [x[1] for x in variant_set_BF]\n",
    "\n",
    "    unscaled_log_posteriors = [ log_bayes_factors[i] + priors[i] for i in range(len(log_bayes_factors))]\n",
    "\n",
    "    scaled_log_posteriors = numpy.array(unscaled_log_posteriors) - max(unscaled_log_posteriors)\n",
    "\n",
    "    scaled_posteriors = [math.exp(x) for x in scaled_log_posteriors]\n",
    "\n",
    "    calib_factor = sum([math.exp(x) for x in scaled_log_posteriors])\n",
    "\n",
    "    posteriors = [x/calib_factor for x in [math.exp(x) for x in scaled_log_posteriors]]\n",
    "    \n",
    "    aug_posteriors = [(variant_set_BF[i][0], posteriors[i]) for i in range(len(posteriors))]\n",
    "    \n",
    "    aug_posteriors.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return aug_posteriors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_variant_set_BFs(data,k,v=0.1,prior='binomial'):\n",
    "    \"\"\"\n",
    "    Calculate variant set posteriors with a binomial prior as normal,\n",
    "    searching all variant sets up till size k.\n",
    "    v is the prior variance on beta.\n",
    "    data has the format (z,LD,n) where z is the effect sizes, \n",
    "    LD is the linkage disequilibrium matrix, and n is the \n",
    "    number of samples.\n",
    "    \"\"\"\n",
    "    bayes_factors = []\n",
    "    for i in range(1,k):\n",
    "        for subset in itertools.combinations(range(len(data[0])),i):\n",
    "            z = select_snps(data[0], subset)\n",
    "            cov = select_cov(data[1],subset)\n",
    "            n = data[2]\n",
    "            bayes_factors.append((subset, calc_BF(z, cov,n,v)))\n",
    "    \n",
    "    bayes_factors.sort(key=lambda x: x[1], reverse=True)\n",
    "    return bayes_factors\n",
    "\n",
    "\n",
    "\n",
    "def get_neighbourhood(subset, data):\n",
    "    total_set = set(range(1, len(data[0])))\n",
    "    out_set = list(total_set - set(subset))\n",
    "\n",
    "    delete_neighbourhood = []\n",
    "    add_neighbourhood = []\n",
    "    change_neighbourhood = []\n",
    "\n",
    "    for k in subset:\n",
    "        neighbour = copy(subset)\n",
    "        neighbour.remove(k)\n",
    "        delete_neighbourhood.append(neighbour)\n",
    "\n",
    "\n",
    "    for m in out_set:\n",
    "        neighbour = copy(subset)\n",
    "        neighbour.append(m)\n",
    "        add_neighbourhood.append(neighbour)\n",
    "\n",
    "    for k in subset:\n",
    "        for m in out_set:\n",
    "            neighbour = copy(subset)\n",
    "            neighbour.remove(k)\n",
    "            neighbour.append(m)\n",
    "            change_neighbourhood.append(neighbour)\n",
    "\n",
    "    neighbourhood = delete_neighbourhood + add_neighbourhood + change_neighbourhood\n",
    "    return neighbourhood\n",
    "\n",
    "\n",
    "def calc_neighbourhood_and_get_max(neighbourhood, data, subset_score_hash):\n",
    "    max_bf = -float('inf')\n",
    "    max_subset = []\n",
    "\n",
    "    for subset in neighbourhood:\n",
    "        z = select_snps(data1[0], subset)\n",
    "        cov = select_cov(data1[1],subset)\n",
    "        n = data1[2]\n",
    "\n",
    "        try:\n",
    "            subset_bf = subset_score_hash[str(sorted(subset))]\n",
    "            if subset_bf > max_bf:\n",
    "                max_bf = subset_bf\n",
    "                max_subset = subset\n",
    "\n",
    "        except KeyError:\n",
    "            z = select_snps(data[0], subset)\n",
    "            cov = select_cov(data[1],subset)\n",
    "            n = data[2]\n",
    "            subset_bf = calc_BF(z, cov,n,v)\n",
    "            subset_score_hash[str(sorted(subset))] = subset_bf\n",
    "\n",
    "            if subset_bf > max_bf:\n",
    "                max_bf = subset_bf\n",
    "                max_subset = subset\n",
    "        \n",
    "    return (max_subset, max_bf)\n",
    "\n",
    "\n",
    "def stochastic_search(data,start):\n",
    "    subset_score_hash = {'[]':0}\n",
    "    subset_walk = []\n",
    "    subset = start\n",
    "\n",
    "    for i in range(30):\n",
    "        neighbourhood = get_neighbourhood(subset,data)\n",
    "        max_subset, max_bf = calc_neighbourhood_and_get_max(neighbourhood,data, subset_score_hash)\n",
    "        if max_subset in [x[0] for x in subset_walk]:\n",
    "            subset_walk.append((max_subset, max_bf))\n",
    "            return subset_walk\n",
    "        else:\n",
    "            subset_walk.append((max_subset, max_bf))\n",
    "            subset = max_subset\n",
    "    \n",
    "    return subset_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([9, 20, 10, 3, 4, 29], 494.57106356274886),\n",
       " ([9, 20, 3, 4, 29, 33], 507.17996796802106),\n",
       " ([9, 3, 4, 29, 33, 32], 524.08717205873381),\n",
       " ([9, 3, 29, 33, 32, 26], 526.28886807989363),\n",
       " ([3, 29, 33, 32, 26, 28], 533.96668645256614),\n",
       " ([29, 33, 32, 26, 28], 536.2326006758949),\n",
       " ([29, 33, 32, 26, 28, 30], 535.0088713120399),\n",
       " ([29, 33, 32, 26, 28], 536.2326006758949)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_tss_1=numpy.load('../data/raw/summary_stats_g1_tss60.npy')[0]\n",
    "s_tss_2=numpy.load('../data/raw/summary_stats_g2_tss60.npy')[0]\n",
    "LD_tss_1=numpy.load('../data/raw/LD_g1_TSS60.npy')\n",
    "LD_tss_2=numpy.load('../data/raw/LD_g2_TSS60.npy')\n",
    "n1 = 10000\n",
    "n2 = 1000\n",
    "z1 = numpy.array(numpy.divide(s_tss_1['beta'],numpy.sqrt(s_tss_1['var_beta'])))\n",
    "z2 = numpy.array(numpy.divide(s_tss_2['beta'],numpy.sqrt(s_tss_2['var_beta'])))\n",
    "z1 = numpy.ndarray.flatten(z1)\n",
    "z2 = numpy.ndarray.flatten(z2)\n",
    "\n",
    "\n",
    "\n",
    "### Initialise hyper parameters\n",
    "k=3\n",
    "v=0.1\n",
    "data1 = (z1, LD_tss_1, 10000)\n",
    "data2 = (z2, LD_tss_2, 1000)\n",
    "\n",
    "stochastic_search(data2,[9,20,10,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    %reset -f\n",
    "    import sys\n",
    "    sys.path.append('/Users/fonz/Projects/Notebooks/Fine-mapping/src')\n",
    "    import models\n",
    "    import numpy\n",
    "    import math\n",
    "\n",
    "    s_tss_1=numpy.load('../data/raw/summary_stats_g1_tss60.npy')[0]\n",
    "    s_tss_2=numpy.load('../data/raw/summary_stats_g2_tss60.npy')[0]\n",
    "    LD_tss_1=numpy.load('../data/raw/LD_g1_TSS60.npy')\n",
    "    LD_tss_2=numpy.load('../data/raw/LD_g2_TSS60.npy')\n",
    "\n",
    "    ### Generate z arrays\n",
    "\n",
    "    n1 = 10000\n",
    "    n2 = 1000\n",
    "    z1 = numpy.array(numpy.divide(s_tss_1['beta'],numpy.sqrt(s_tss_1['var_beta'])))\n",
    "    z2 = numpy.array(numpy.divide(s_tss_2['beta'],numpy.sqrt(s_tss_2['var_beta'])))\n",
    "    z1 = numpy.ndarray.flatten(z1)\n",
    "    z2 = numpy.ndarray.flatten(z2)\n",
    "\n",
    "    ### Initialise hyper parameters\n",
    "    k=3\n",
    "    data1 = (z1, LD_tss_1, 10000)\n",
    "    data2 = (z2, LD_tss_2, 1000)\n",
    "\n",
    "    ### Calculate variant set Bayes Factors\n",
    "    set1 = models.bayes_factors.calc_variant_set_BFs(data1,k)\n",
    "    set2 = models.bayes_factors.calc_variant_set_BFs(data2,k)\n",
    "\n",
    "    ### Calculate variant set posteriors\n",
    "    posteriors1 = models.bayes_factors.calc_posterior(set1)\n",
    "    posteriors2 = models.bayes_factors.calc_posterior(set2)\n",
    "\n",
    "    posteriors1.sort(key=lambda x: x[1], reverse=True)\n",
    "    posteriors2.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    posteriors2[0:10]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
