{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Initialisation-+-tests\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialisation + tests</a></div><div class=\"lev1\"><a href=\"#Introduction\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1\"><a href=\"#Single-trait-Fine-mapping\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Single trait Fine-mapping</a></div><div class=\"lev2\"><a href=\"#Bayes-Factor-Computation\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Bayes Factor Computation</a></div><div class=\"lev3\"><a href=\"#Derivation-of-$z$-values\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Derivation of <span class=\"MathJax_Preview\" style=\"color: inherit;\"><span class=\"MJXp-math\" id=\"MJXp-Span-1\"><span class=\"MJXp-mi MJXp-italic\" id=\"MJXp-Span-2\">z</span></span></span><span class=\"MathJax MathJax_Processing\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\"></span><script type=\"math/tex\" id=\"MathJax-Element-1\">z</script> values</a></div><div class=\"lev3\"><a href=\"#Calculation-of-Bayes-Factor\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Calculation of Bayes Factor</a></div><div class=\"lev3\"><a href=\"#Calculation-of-Posterior\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Calculation of Posterior</a></div><div class=\"lev3\"><a href=\"#Implementation\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Implementation</a></div><div class=\"lev3\"><a href=\"#Example\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Example</a></div><div class=\"lev2\"><a href=\"#Trait-simulation\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Trait simulation</a></div><div class=\"lev3\"><a href=\"#Explanation\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Explanation</a></div><div class=\"lev3\"><a href=\"#Implementation\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Implementation</a></div><div class=\"lev3\"><a href=\"#Example\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Example</a></div><div class=\"lev1\"><a href=\"#Colocalisation\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Colocalisation</a></div><div class=\"lev1\"><a href=\"#Tests\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Tests</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation + tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "### Load modules and data\n",
    "\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import stats\n",
    "import pdb\n",
    "from sklearn import preprocessing\n",
    "import copy\n",
    "from unittest import *\n",
    "import itertools\n",
    "from bidict import bidict\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I implement basic fine-mapping methods. Firstly I implement a basic method to calculated Bayes Factors given sets of SNPs and their effect sizes using the LD structure calculated from 1000 genomes, from which I calculate posterior probabilities of gene sets. Then I simulate trait data with specified effect sizes, and generate summary statistics from these data. Following this, I implement a colocalisation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single trait Fine-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Factor Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation of $z$ values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we assume that the trait $y$ is modelled as:\n",
    "\n",
    "$$ y = X\\beta + \\epsilon $$\n",
    "\n",
    "Where $X$ is an $n$x$m$ matrix of values consisting of 0,1,2 denoting whether a SNP is homozygous to the common allele, heterozygous, or homozygous to the rare allele respectively. $n$ denotes the number of samples, and $m$ the number of causitive SNPs.\n",
    "\n",
    "We scale $X$ such that $\\frac{1}{n}\\sum^{n}_{i=1} X_{ij} = 0$, and $\\frac{1}{n}\\sum^{n}_{i=1} X^2_{ij} = 1$ for $j = 1,2, ... m$. We also scale $y$ such that $\\frac{1}{n}\\sum^n_{i=1} y_i = 0$ and $\\frac{1}{n}\\sum^n_{i=1} y_i^2 = 1$.\n",
    "\n",
    "We assume $\\epsilon$ ~ $N(0, \\frac{1}{\\tau} I_n)$. We also assume $\\beta$ has a prior normal distribution $N(0,\\nu \\frac{1}{\\tau})$. $\\nu$ is diagonal, $\\beta$ and $\\epsilon$ are independent and we assume all SNPs have the same prior variance $\\sigma^2 \\frac{1}{\\tau}$. Therefore $\\nu = \\sigma^2 I_m$.\n",
    "\n",
    "Now given this prior on $\\beta$, and using $X$ and $\\epsilon$, we can deduce the expectation and mean of $y$.\n",
    "\n",
    "$$E(y \\: | \\: \\tau, X) = E(E(y \\: | \\: \\tau,X,\\beta)) = E(X \\beta) = 0$$ \n",
    "\n",
    "<sub>[ *since* $E(\\beta) = 0$ ]</sub>\n",
    "\n",
    "$$ Var(y \\: | \\: \\tau, X) = E(Var(y \\: | \\tau, X, \\beta)) + Var(E(y \\: | \\: \\tau, X, \\beta)) $$\n",
    "\n",
    "<sub>[ *since* $Var(X \\: | \\: Y) = E(Var(X \\: | \\: Y)) + Var(E(X \\: | \\: Y))$ ]</sub>\n",
    "\n",
    "$$ = E(\\frac{1}{\\tau}I_n) + Var(X \\beta)$$\n",
    "\n",
    "$$ = \\frac{1}{\\tau}( I_n + X \\nu X^T)$$\n",
    "\n",
    "Now, since y is a linear transformation of a multivariate normal random vector,\n",
    "\n",
    "$$ y \\:|\\: \\tau, X \\sim N \\left( 0,\\frac{1}{\\tau}( I_n + X \\nu X^T)) \\right) $$\n",
    "\n",
    "The null distribution is when $\\beta = 0$. In which case,\n",
    "\n",
    "$$y \\:|\\: \\tau, X \\sim N \\left( 0,\\frac{1}{\\tau}I_n \\right) $$\n",
    "\n",
    "Now consider a new variable $z = \\sqrt{\\frac{\\tau}{n}} X^{T}y$:\n",
    "\n",
    "$$ z ~ \\sim N \\left( 0, \\frac{X^T}{n}(I_n + X \\nu X^T) X \\right)$$\n",
    "\n",
    "$$ = N \\left( 0, \\left(\\frac{X^TX}{n} + \\frac{X^TX \\nu X^TX}{n}\\right) \\right)$$\n",
    "\n",
    "Now let $\\Sigma_x = \\frac{X^T X}{n}$. Since all column in $X$ are standardised, this is equivalent to the correlation matrix or, more importantantly, the linkage disequilibirum structure of the SNPs which can be derived from the 1000 genomes data.\n",
    "\n",
    "Then we have:\n",
    "\n",
    "$$ z \\sim N(0, \\Sigma_x + \\Sigma_x n\\nu \\Sigma_x) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of Bayes Factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Bayes Factor* is the ratio of the likelihood functions under the alternative hypothesis, and under the null hypothesis. It is equivalent to the likelihood ratio.\n",
    "\n",
    "$P_1(z \\:|\\: \\tau, X)$, the likelihood of $z$ under our alternate hypothesis, i.e. when $\\nu \\neq 0$ is:\n",
    "\n",
    "$$ P_1(z \\:|\\: \\tau, X) = 2\\pi^{-\\frac{n}{2}} | \\Sigma_x + \\Sigma_x n\\nu \\Sigma_x |^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}z^T(\\Sigma_x + \\Sigma_x n\\nu \\Sigma_x)^{-1}z\\right)$$\n",
    "\n",
    "$P_0(z \\:| \\: \\tau, X)$, the likelihood of $z$ under the null hypothesis when $\\nu = 0$ is:\n",
    "\n",
    "$$P_0(z \\:| \\: \\tau, X) = 2\\pi^{-\\frac{n}{2}} |\\Sigma_x|^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}z^T(\\Sigma_x)^{-1}z\\right)$$\n",
    "\n",
    "Therefore we calculate the Bayes Factor as:\n",
    "\n",
    "$$ \\frac{\n",
    "| \\Sigma_x + n\\nu \\Sigma_x^2 |^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}z^T(\\Sigma_x + \\Sigma_x n\\nu \\Sigma_x)^{-1}z\\right)\n",
    "}{\n",
    "|\\Sigma_x|^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}z^T(\\Sigma_x)^{-1}z\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "We assume that $X$ has full column rank, and that $\\Sigma_x$ also has rank $m$ and is non-singular. That is to say, we assume that no two snps are in full linkage disequilibrium.\n",
    "\n",
    "Using the Woodberry matrix identity:\n",
    "\n",
    "$$\n",
    "(\\Sigma_x + \\Sigma_x n\\nu \\Sigma_x)^{-1} = \\Sigma_x^{-1} - ((n\\nu)^{-1} + \\Sigma_x)^{-1}\n",
    "$$\n",
    "\n",
    "Therefore the resulting Bayes Factor is:\n",
    "\n",
    "$$\n",
    "|I_m + n\\nu \\Sigma_x|^\\frac{1}{2} \\exp(\\frac{1}{2}z^T((n\\nu)^{-1} + \\Sigma_x)^{-1}z)\n",
    "$$\n",
    "\n",
    "Crucially, this only depends on inverting matrices of size m, our candidate gene set. Therefore we compute these Bayes Factors using sets of candidate SNPs of size m, and choose the set with the highest calculated Bayes Factor.\n",
    "\n",
    "In practice, we recieve $\\beta$, $se(\\beta)$, and the SNP linkage disequilibrium structure $\\Sigma_x$.\n",
    "\n",
    "Since both $X$ and $y$ are normalised, \n",
    "\n",
    "$$\\beta = \\frac{X^T y}{n}$$\n",
    "\n",
    "Also, \n",
    "$$\\tau = \\frac{1}{\\sigma^2}, \\:\\: se(\\epsilon) = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "where $\\sigma$ is the observed standard deviation of the errors $\\epsilon$.\n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "se(\\epsilon) = \\frac{1}{\\sqrt{n\\tau}}\n",
    "$$\n",
    "\n",
    "Therefore we generate the $z$ vector exactly with and $se$ is the standard error:\n",
    "\n",
    "$$\n",
    "\\frac{\\beta}{se(\\beta)} = \\sqrt{\\frac{\\tau}{n}} X^{T}y = z\n",
    "$$\n",
    "\n",
    "The Bayes Factor can then be directly calculated using $z$ and $\\Sigma_x$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place a binomial prior on candidate gene sets. If our gene set $G$ has size $m$, we assume that each SNPs has probability  $p = \\frac{1}{m}$ of being causal. Therefore the prior probability of a causal gene set with size $l$ is:\n",
    "\n",
    "$$\n",
    "P(G) = p^l(1-p)^{m-l}\n",
    "$$\n",
    "\n",
    "Therefore using Bayes Theorem:\n",
    "\n",
    "$$\n",
    "P(G \\: | \\: X) = \\frac{P(X \\: | \\: G) \\times P(G)}{P(X)}\n",
    "$$\n",
    "\n",
    "to calculate posterior probabilities of the gene sets where $P(X \\: | \\: G)$ is calculated from the normalised Bayes Factors.\n",
    "\n",
    "However when we calculated the Bayes Factors, these are not exactly the likelihoods. They are however far easier to compute.\n",
    "\n",
    "The Bayes Factors we have calculated are equivalent to:\n",
    "\n",
    "$$\n",
    "\\frac{P(X \\: | \\: G)}{P(X \\: | \\: G_0)}\n",
    "$$\n",
    "\n",
    "where $G_0$ is the null hypothesis that no gene-set is casual.\n",
    "\n",
    "However, since $P(X \\: | \\: G_0)$ is a constant for all gene-sets, this is proportional to the likelihood term. Therefore we can normalise to output the posterior probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "### Create selection of SNPs\n",
    "def select_snps(z, subset):\n",
    "    return [z[i] for i in subset]\n",
    "\n",
    "#example\n",
    "# for subset in it.combinations(range(len(z1)),3):\n",
    "#     print subset, select_snps(z1, subset)    \n",
    "\n",
    "\n",
    "\n",
    "### Select covariance submatrix\n",
    "\n",
    "def select_cov(cov, subset):\n",
    "    return cov[np.ix_(subset,subset)]\n",
    "\n",
    "#example   \n",
    "#select_cov(LD_tss_1, (0,1,5))\n",
    "\n",
    "### Calculate Bayes Factor\n",
    "\n",
    "def calc_BF(z, cov,n,v=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the Bayes factor of a single set of candidate SNPs effect sizes z,\n",
    "    covariance matrix cov, a prior variance on beta v, and a sample\n",
    "    size n.\n",
    "    \"\"\"\n",
    "    z = np.matrix(z)\n",
    "    z = z.T\n",
    "    v_matrix = np.matrix(np.eye(len(z)) * v)\n",
    "#     pdb.set_trace()\n",
    "    coeff = 1. / math.sqrt(np.linalg.det((np.matrix(np.eye(len(z))) + n * v_matrix * np.matrix(cov))))\n",
    "    exponent = 0.5* z.T * np.matrix(np.linalg.pinv((n*v_matrix).I + cov)) * z\n",
    "    return np.array(math.log(coeff) + exponent)[0][0]\n",
    "\n",
    "# example\n",
    "# subset = (0,1,5,8)\n",
    "# cov = select_cov(LD_tss_1, subset)\n",
    "# z = select_snps(z1, subset)\n",
    "# v = np.eye(len(z))/1000\n",
    "# n = 1000\n",
    "# calc_BF(z,cov,v,n)\n",
    "\n",
    "def calc_prior(x,m,prior='binomial'):\n",
    "    if prior == 'binomial':\n",
    "        p = 1./m\n",
    "        l = len(x)\n",
    "        return p**l * (1-p)**(m-l)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# example\n",
    "# calc_prior((1,3,5),30)\n",
    "    \n",
    "def calc_posterior(variant_set_BF,prior='binomial'):\n",
    "    \n",
    "    priors = [math.log(calc_prior(x[0],30)) for x in variant_set_BF]\n",
    "    \n",
    "    log_bayes_factors = [x[1] for x in variant_set_BF]\n",
    "\n",
    "    unscaled_log_posteriors = [ log_bayes_factors[i] + priors[i] for i in range(len(log_bayes_factors))]\n",
    "\n",
    "    scaled_log_posteriors = np.array(unscaled_log_posteriors) - max(unscaled_log_posteriors)\n",
    "\n",
    "    scaled_posteriors = [math.exp(x) for x in scaled_log_posteriors]\n",
    "\n",
    "    calib_factor = sum([math.exp(x) for x in scaled_log_posteriors])\n",
    "\n",
    "    posteriors = [x/calib_factor for x in [math.exp(x) for x in scaled_log_posteriors]]\n",
    "    \n",
    "    aug_posteriors = [(variant_set_BF[i][0], posteriors[i]) for i in range(len(posteriors))]\n",
    "    \n",
    "    aug_posteriors.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return aug_posteriors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_variant_set_BFs(data,k,v=0.1,prior='binomial'):\n",
    "    \"\"\"\n",
    "    Calculate variant set posteriors with a binomial prior as normal,\n",
    "    searching all variant sets up till size k.\n",
    "    v is the prior variance on beta.\n",
    "    data has the format (z,LD,n) where z is the effect sizes, \n",
    "    LD is the linkage disequilibrium matrix, and n is the \n",
    "    number of samples.\n",
    "    \"\"\"\n",
    "    bayes_factors = []\n",
    "    for i in range(1,k):\n",
    "        for subset in it.combinations(range(len(data[0])),i):\n",
    "            z = select_snps(data[0], subset)\n",
    "            cov = select_cov(data[1],subset)\n",
    "            n = data[2]\n",
    "            bayes_factors.append((subset, calc_BF(z, cov,n,v)))\n",
    "    \n",
    "    bayes_factors.sort(key=lambda x: x[1], reverse=True)\n",
    "    return bayes_factors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     19
    ],
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "s_tss_1=np.load('summary_stats_g1_tss60.npy')[0]\n",
    "s_tss_2=np.load('summary_stats_g2_tss60.npy')[0]\n",
    "LD_tss_1=np.load('LD_g1_TSS60.npy')\n",
    "LD_tss_2=np.load('LD_g2_TSS60.npy')\n",
    "\n",
    "### Generate z arrays\n",
    "\n",
    "n1 = 10000\n",
    "n2 = 1000\n",
    "z1 = np.array(np.divide(s_tss_1['beta'],np.sqrt(s_tss_1['var_beta'])))\n",
    "z2 = np.array(np.divide(s_tss_2['beta'],np.sqrt(s_tss_1['var_beta'])))\n",
    "z1 = np.ndarray.flatten(z1)\n",
    "z2 = np.ndarray.flatten(z2)\n",
    "\n",
    "### Initialise hyper parameters\n",
    "k=3\n",
    "data1 = (z1, LD_tss_1, 10000)\n",
    "data2 = (z2, LD_tss_2, 1000)\n",
    "\n",
    "### Calculate variant set Bayes Factors\n",
    "set1 = calc_variant_set_BFs(data1,k)\n",
    "set2 = calc_variant_set_BFs(data2,k)\n",
    "\n",
    "### Calculate variant set posteriors\n",
    "posteriors1 = calc_posterior(set1)\n",
    "posteriors2 = calc_posterior(set2)\n",
    "\n",
    "posteriors1.sort(key=lambda x: x[1], reverse=True)\n",
    "posteriors2.sort(key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((27, 29), 0.9151178367714483),\n",
       " ((29,), 0.02660978343371104),\n",
       " ((1, 29), 0.01814290094185906),\n",
       " ((6, 29), 0.014384187969434005),\n",
       " ((28, 29), 0.0072543067927032835),\n",
       " ((29, 30), 0.003287058453751547),\n",
       " ((16, 29), 0.003015627470309419),\n",
       " ((25, 29), 0.002901065736140464),\n",
       " ((0, 29), 0.002500323472232103),\n",
       " ((2, 29), 0.0010426464045647608)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posteriors2[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given genotype data and an LD structure, simulate a trait which is linearly associated with a variant, or a set of variants. Here I generate a large $m \\times n$ matrix ($m$=number of samples, $n$=number of SNPs), with $0,1,2$ as elements.\n",
    "\n",
    "Then, I can choose a set of SNPs, and from these SNPs I generate a trait with a linear model with a given parameter $\\beta$, as well as an unexplained variance parameter $\\epsilon$.\n",
    "\n",
    "Following this, I try to recover these sets of SNPs. I generate p-values for each SNP being associated with the trait, by individually building univariate linear models for each SNPs, as I understand summary statistics are generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "### Sample genotypes\n",
    "\n",
    "def simulate_genotype(n,m,geno_dist):\n",
    "    \"\"\"\n",
    "    Simulate a genotype of n samples and m causal SNPs with specified genotype distribution for (0,1,2).\n",
    "    \"\"\"\n",
    "    X=np.zeros([n,m])\n",
    "    for i in range(m):\n",
    "        X[:,i] = [np.random.choice(a=[0,1,2],p=geno_dist) for x in range(n)]\n",
    "    return np.array(X)\n",
    "\n",
    "###example\n",
    "# X = simulate_genotype(n=10000,m=30,geno_dist=[0.85,0.1,0.05])\n",
    "\n",
    "def simulate_traits(X,snp_group,eps=0.5):\n",
    "    \"\"\"\n",
    "    SNPs in the form e.g. {3: 0.9, 5:0.4, 8:0.5}. Dictionary values are the linear model coefficients (beta values).\n",
    "    eps is the level of unexplained variance. X is the genotype information.\n",
    "    \"\"\"\n",
    "    beta = np.array(snp_group.values()).T\n",
    "    snps = snp_group.keys()\n",
    "    eps_vector = np.array(np.random.normal(0,eps,X.shape[0])).T\n",
    "    return np.add(np.dot(X[:,snps], beta), eps_vector)\n",
    "    \n",
    "# examples\n",
    "# y = simulate_traits(X,eps=0.5,snp_group={3: 5, 9: 3})\n",
    "\n",
    "def build_linear_models(X,y):\n",
    "    \"\"\"\n",
    "    Build univariate linear models for each SNP column in X against the trait y.\n",
    "    \"\"\"\n",
    "    return [stats.linregress(X[:,i],y) for i in range(X.shape[1])]\n",
    "\n",
    "# example\n",
    "# models1 = [x for x in build_linear_models(X,y)]\n",
    "\n",
    "def calc_effect_sizes(models):\n",
    "    \"\"\"\n",
    "    Calculate the effect sizes = beta / se(beta) of individual SNPs towards the traits.\n",
    "    Takes in a list of linear regression models.\n",
    "    \"\"\"\n",
    "    return [x.slope / x.stderr for x in models]\n",
    "\n",
    "# example\n",
    "# z1 = [x.slope / x.stderr for x in models1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 5} [((1,), 0.9050352515170708), ((1, 21), 0.003189029568249363), ((1, 25), 0.00318428426718765), ((1, 19), 0.003161674088441622), ((1, 4), 0.0031344545531106003)]\n",
      "{1: 5, 3: 6} [((1, 3), 0.9083736228868016), ((1, 3, 13), 0.0031873943086928548), ((1, 3, 10), 0.0031412730321097606), ((1, 3, 26), 0.003138966388610109), ((1, 3, 17), 0.0031380659516668206)]\n",
      "{1: 5, 3: 6, 15: 3} [((1, 3, 15), 0.9150552356086875), ((1, 3, 12, 15), 0.0031637810581904495), ((1, 3, 4, 15), 0.0031548310641800084), ((1, 3, 15, 19), 0.003154222576982418), ((1, 3, 15, 27), 0.0031541062648322094)]\n",
      "{1: 5, 3: 6, 25: 1, 15: 3} [((1, 3, 15, 25), 1.0), ((1, 3, 15), 3.0459784689226484e-28), ((1, 3, 9, 15), 1.0914551735029302e-30), ((1, 3, 13, 15), 1.083211641042767e-30), ((1, 3, 15, 21), 1.0756922570942834e-30)]\n"
     ]
    }
   ],
   "source": [
    "snp_groups = [{1: 5}, {1: 5, 3: 6}, {1: 5, 3: 6, 15:3}, {1: 5, 3: 6, 15:3, 25:1}]\n",
    "\n",
    "for g in snp_groups:\n",
    "    n = 10000\n",
    "\n",
    "    ### simulate genotypes\n",
    "    X = simulate_genotype(n=10000,m=30,geno_dist=[0.85,0.1,0.05])\n",
    "    ### scale columns\n",
    "    X = preprocessing.scale(X)\n",
    "\n",
    "    ### calculate LD matrix\n",
    "    LD_matrix = np.corrcoef(X,rowvar=0)\n",
    "\n",
    "    ### simulate traits\n",
    "    y = simulate_traits(X,eps=0.5,snp_group=g)\n",
    "    ### scale traits\n",
    "    y = preprocessing.scale(y)\n",
    "\n",
    "    t_statistics = build_linear_models(X,y)\n",
    "\n",
    "    beta = [x.slope for x in t_statistics]\n",
    "    se_beta = [x.stderr for x in t_statistics]\n",
    "\n",
    "    ###calcuate z\n",
    "\n",
    "    z =  np.divide(beta, se_beta)\n",
    "\n",
    "    simulated_effectsize_data = ([x*np.sqrt(n) for x in beta], LD_matrix, n)\n",
    "\n",
    "    gene_set_BFs = calc_variant_set_BFs(simulated_effectsize_data,k=5,v=0.01)\n",
    "\n",
    "    gene_set_posteriors = calc_posterior(gene_set_BFs)\n",
    "    print g, gene_set_posteriors[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colocalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible to ascertain whether two traits are due to the same causal variant? This is the aim of colocalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First simulate two traits with different effect sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_colocalised(X, trait1, trait2,db=0):\n",
    "    \"\"\"\n",
    "    With respect to a shared genotype X, Determine whether trait1 and trait2 are colocalised.\n",
    "    I.e. whether there is evidence that they share a genetic basis.\n",
    "    \"\"\"\n",
    "\n",
    "    ### generate individual linear models\n",
    "    models1 = build_linear_models(X,y1)\n",
    "    models2 = build_linear_models(X,y2)\n",
    "\n",
    "    ### pull out slope and standard error terms.\n",
    "    beta1 = [x.slope for x in models1]\n",
    "    se_beta1 = [x.stderr for x in models1]\n",
    "\n",
    "    beta2 = [x.slope for x in models2]\n",
    "    se_beta2 = [x.stderr for x in models2]\n",
    "\n",
    "    ### calculate z scores\n",
    "    simulated_effectsize_data1 = ([x*np.sqrt(n) for x in beta1], LD_matrix, n)\n",
    "    simulated_effectsize_data2 = ([x*np.sqrt(n) for x in beta2], LD_matrix, n)\n",
    "\n",
    "    ### generate the gene set Bayes Factors\n",
    "    gene_set_BFs1 = calc_variant_set_BFs(simulated_effectsize_data1,k=4,v=0.01)\n",
    "    gene_set_BFs2 = calc_variant_set_BFs(simulated_effectsize_data2,k=4,v=0.01)\n",
    "    \n",
    "\n",
    "    ### calculate the posteriors\n",
    "    gene_set_posteriors1 = calc_posterior(gene_set_BFs1)\n",
    "    gene_set_posteriors2 = calc_posterior(gene_set_BFs2)\n",
    "    \n",
    "    if db == 1: \n",
    "        \n",
    "        print gene_set_BFs1[0:10]\n",
    "        print gene_set_BFs2[0:10]\n",
    "        \n",
    "        print gene_set_posteriors1[0:10]\n",
    "        print gene_set_posteriors2[0:10]\n",
    "\n",
    "\n",
    "    ### sort by posterior size\n",
    "    gene_set_posteriors1.sort(key=lambda x: x[0], reverse=False)\n",
    "    gene_set_posteriors2.sort(key=lambda x: x[0], reverse=False)\n",
    "\n",
    "    ### select just toe posteriors\n",
    "    posteriors1 = [x[1] for x in gene_set_posteriors1]\n",
    "    posteriors2 = [x[1] for x in gene_set_posteriors2]\n",
    "\n",
    "    ### generate cartesian product from the posteriors\n",
    "    cart_product = list(itertools.product(posteriors1,posteriors2))\n",
    "\n",
    "    gene_set_len1 = len(gene_set_posteriors1)\n",
    "    gene_set_len2 = len(gene_set_posteriors2)\n",
    "\n",
    "    ### calculate colocalisation posteriors with a specificed scoring function.\n",
    "    colocalisations = np.array(map(lambda x: min(x[0],x[1]), cart_product)).reshape(gene_set_len1,gene_set_len2)\n",
    "\n",
    "\n",
    "    ### pull out sorted set list\n",
    "    sorted_setlist1 = [x[0] for x in gene_set_posteriors1]\n",
    "    sorted_setlist2 = [x[0] for x in gene_set_posteriors2]\n",
    "\n",
    "    if db == 1:\n",
    "        \n",
    "        ###  create bidirectional map from gene_set to positon in colocalisation array\n",
    "        setlist_1map = bidict([(sorted_setlist1[i],i) for i in range(len(sorted_setlist1))])\n",
    "        setlist_2map = bidict([(sorted_setlist1[i],i) for i in range(len(sorted_setlist2))])\n",
    "\n",
    "        bf_1map = dict(gene_set_BFs1)\n",
    "        bf_2map = dict(gene_set_BFs2)\n",
    "\n",
    "\n",
    "        posterior1_map = dict(gene_set_posteriors1)\n",
    "        posterior2_map = dict(gene_set_posteriors2)\n",
    "        pdb.set_trace()\n",
    "\n",
    "    ### output total evidence for colocalisation\n",
    "    return sum([colocalisations[i][i] for i in range(colocalisations.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({8: 6}, {8: 6}) True\n",
      "({8: 6}, {8: 10}) True\n",
      "({8: 6}, {10: 6}) False\n",
      "({8: 6, 10: 4}, {8: 6, 10: 4}) True\n",
      "({8: 6, 10: 4}, {8: 6, 10: 8}) True\n",
      "({8: 6, 10: 4}, {8: 6, 15: 4}) False\n",
      "({8: 6, 10: 4, 12: 3}, {8: 6, 10: 4, 12: 3}) True\n",
      "({8: 6, 10: 4, 12: 3}, {8: 6, 10: 4, 12: 8}) True\n",
      "({8: 6, 10: 4, 12: 3}, {8: 6, 10: 4, 15: 3}) False\n"
     ]
    }
   ],
   "source": [
    "gene_sets = [({8:6},{8:6}),\n",
    "             ({8:6},{8:10}),\n",
    "             ({8:6},{10:6}),\n",
    "             ({8:6, 10:4},{8:6, 10:4}),\n",
    "             ({8:6, 10:4},{8:6, 10:8}),\n",
    "             ({8:6, 10:4},{8:6, 15:4}),\n",
    "             ({8:6, 10:4, 12:3},{8:6, 10:4, 12:3}),\n",
    "             ({8:6, 10:4, 12:3},{8:6, 10:4, 12:8}),\n",
    "             ({8:6, 10:4, 12:3},{8:6, 10:4, 15:3}),\n",
    "            ]\n",
    "\n",
    "for g in gene_sets:\n",
    "    ### set sample size\n",
    "    n = 10000\n",
    "\n",
    "    ### simulate genotypes and scale columns\n",
    "    X = preprocessing.scale(simulate_genotype(n, 30, (0.85, 0.1, 0.05)))\n",
    "\n",
    "    ### calculate LD matrix\n",
    "    LD_matrix = np.corrcoef(X,rowvar=0)\n",
    "\n",
    "\n",
    "    ### simulate two traits and scale columns\n",
    "    y1 = preprocessing.scale(simulate_traits(X, g[0]))\n",
    "    y2 = preprocessing.scale(simulate_traits(X, g[1]))\n",
    "\n",
    "    print g, is_colocalised(X,y1,y2,db=0) > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "CPU times: user 364 ms, sys: 7.86 ms, total: 372 ms\n",
      "Wall time: 371 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestStringMethods(unittest.TestCase):\n",
    "\n",
    "    def test_upper(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "\n",
    "    def test_isupper(self):\n",
    "        self.assertTrue('FOO'.isupper())\n",
    "        self.assertFalse('Foo'.isupper())\n",
    "\n",
    "    def test_split(self):\n",
    "        s = 'hello world'\n",
    "        self.assertEqual(s.split(), ['hello', 'world'])\n",
    "        # check that s.split fails when the separator is not a string\n",
    "        with self.assertRaises(TypeError):\n",
    "            s.split(2)\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestStringMethods)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
